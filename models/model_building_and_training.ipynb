{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matidesalegn/Improved-detection-of-fraud-cases-in-e-commerce-and-bank-transactions/blob/task-2/models/model_building_and_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGSoaggxpLFf"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Processed Data\n",
        "### First, let's load the processed data for both datasets:\n",
        "\n",
        "### Processed Fraud Data with Country: ../data/processed/processed_fraud_data_with_country.csv\n",
        "### Processed Credit Card Data: ../data/processed/processed_credit_card_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ehz_GXwpLFh",
        "outputId": "0df33b53-8059-4db7-aa5b-3f268f5b258a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.14.1-py3-none-any.whl (25.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=3.1.9 (from mlflow)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.2)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow) (24.1)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.30)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.5.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<23 (from mlflow)\n",
            "  Downloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow) (1.14.1)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/smmap/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: aniso8601, smmap, querystring-parser, Mako, gunicorn, graphql-core, deprecated, opentelemetry-api, graphql-relay, gitdb, docker, alembic, opentelemetry-semantic-conventions, graphene, gitpython, opentelemetry-sdk, mlflow\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 aniso8601-9.0.1 deprecated-1.2.14 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-22.0.0 mlflow-2.14.1 opentelemetry-api-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-7b4618c94eab>:17: DtypeWarning: Columns (92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  fraud_data = pd.read_csv('processed_fraud_data_with_country.csv')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fraud Data Columns:\n",
            "Index(['user_id', 'purchase_value', 'age', 'ip_address', 'class',\n",
            "       'ip_address_int', 'transaction_count', 'time_since_signup',\n",
            "       'transaction_velocity', 'transaction_time_diff',\n",
            "       ...\n",
            "       'country_Turkmenistan_True', 'country_Ukraine_True',\n",
            "       'country_United Arab Emirates_True', 'country_United Kingdom_True',\n",
            "       'country_United States_True', 'country_Unknown_True',\n",
            "       'country_Uruguay_True', 'country_Uzbekistan_True',\n",
            "       'country_Venezuela_True', 'country_Viet Nam_True'],\n",
            "      dtype='object', length=8571)\n",
            "\n",
            "Credit Card Data Columns:\n",
            "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
            "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
            "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
            "       'Class'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "!pip install mlflow\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer  # Import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "# Load processed data\n",
        "fraud_data = pd.read_csv('processed_fraud_data_with_country.csv')\n",
        "credit_card_data = pd.read_csv('processed_credit_card_data.csv')\n",
        "\n",
        "# Ensure datetime columns are correctly parsed\n",
        "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
        "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
        "\n",
        "# Feature Engineering for fraud_data\n",
        "# Extract numerical features from datetime columns\n",
        "fraud_data['signup_hour'] = fraud_data['signup_time'].dt.hour\n",
        "fraud_data['signup_day'] = fraud_data['signup_time'].dt.day\n",
        "fraud_data['signup_month'] = fraud_data['signup_time'].dt.month\n",
        "fraud_data['signup_year'] = fraud_data['signup_time'].dt.year\n",
        "\n",
        "fraud_data['purchase_hour'] = fraud_data['purchase_time'].dt.hour\n",
        "fraud_data['purchase_day'] = fraud_data['purchase_time'].dt.day\n",
        "fraud_data['purchase_month'] = fraud_data['purchase_time'].dt.month\n",
        "fraud_data['purchase_year'] = fraud_data['purchase_time'].dt.year\n",
        "\n",
        "# Drop original datetime columns\n",
        "fraud_data = fraud_data.drop(columns=['signup_time', 'purchase_time'])\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = fraud_data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Encode categorical features\n",
        "fraud_data = pd.get_dummies(fraud_data, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Check the structure and columns of the datasets\n",
        "print(\"Fraud Data Columns:\")\n",
        "print(fraud_data.columns)\n",
        "print(\"\\nCredit Card Data Columns:\")\n",
        "print(credit_card_data.columns)\n",
        "\n",
        "# Feature and target separation for fraud detection data\n",
        "X_fraud = fraud_data.drop(columns=['class'])  # Features\n",
        "y_fraud = fraud_data['class']                # Target\n",
        "\n",
        "# Feature and target separation for credit card data\n",
        "X_credit = credit_card_data.drop(columns=['Class'])  # Features\n",
        "y_credit = credit_card_data['Class']                # Target\n",
        "\n",
        "# Handle missing values in features\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_fraud = imputer.fit_transform(X_fraud)\n",
        "X_credit = imputer.fit_transform(X_credit)\n",
        "\n",
        "# Handle missing values in target variables\n",
        "y_fraud = y_fraud.fillna(y_fraud.mode()[0])\n",
        "y_credit = y_credit.fillna(y_credit.mode()[0])\n",
        "\n",
        "# Train-test split for fraud data\n",
        "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(X_fraud, y_fraud, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train-test split for credit card data\n",
        "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(X_credit, y_credit, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSxAMbnZpLFj"
      },
      "source": [
        "# Model Selection, Training, and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### We'll use several models to compare their performance:\n",
        "\n",
        "### Logistic Regression\n",
        "### Decision Tree\n",
        "### Random Forest\n",
        "### Gradient Boosting\n",
        "### Multi-Layer Perceptron (MLP)\n",
        "### Convolutional Neural Network (CNN) (for credit card data)\n",
        "### Recurrent Neural Network (RNN) or LSTM (for fraud detection data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Training and Evaluation\n",
        "### Train and Evaluate Models\n",
        "### Here's how you might train and evaluate models for the fraud detection dataset (X_train_fraud, y_train_fraud, X_test_fraud, y_test_fraud). Repeat a similar process for the credit card dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO7yaHSupLFj",
        "outputId": "f80d6fc2-709c-4aab-f840-3739d6bb3e62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 0.9105263157894737\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95      1557\n",
            "           1       0.00      0.00      0.00       153\n",
            "\n",
            "    accuracy                           0.91      1710\n",
            "   macro avg       0.46      0.50      0.48      1710\n",
            "weighted avg       0.83      0.91      0.87      1710\n",
            "\n",
            "============================================================\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.9514619883040936\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      1557\n",
            "           1       0.99      0.46      0.63       153\n",
            "\n",
            "    accuracy                           0.95      1710\n",
            "   macro avg       0.97      0.73      0.80      1710\n",
            "weighted avg       0.95      0.95      0.94      1710\n",
            "\n",
            "============================================================\n",
            "Model: Random Forest\n",
            "Accuracy: 0.952046783625731\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      1557\n",
            "           1       1.00      0.46      0.63       153\n",
            "\n",
            "    accuracy                           0.95      1710\n",
            "   macro avg       0.97      0.73      0.80      1710\n",
            "weighted avg       0.95      0.95      0.94      1710\n",
            "\n",
            "============================================================\n",
            "Model: Gradient Boosting\n",
            "Accuracy: 0.952046783625731\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      1557\n",
            "           1       1.00      0.46      0.63       153\n",
            "\n",
            "    accuracy                           0.95      1710\n",
            "   macro avg       0.97      0.73      0.80      1710\n",
            "weighted avg       0.95      0.95      0.94      1710\n",
            "\n",
            "============================================================\n",
            "Model: MLP\n",
            "Accuracy: 0.9116959064327486\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95      1557\n",
            "           1       1.00      0.01      0.03       153\n",
            "\n",
            "    accuracy                           0.91      1710\n",
            "   macro avg       0.96      0.51      0.49      1710\n",
            "weighted avg       0.92      0.91      0.87      1710\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Initialize models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'MLP': MLPClassifier(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Train and evaluate models for fraud detection data\n",
        "for name, model in models.items():\n",
        "    with mlflow.start_run(run_name=f'{name} on Fraud Data'):\n",
        "        model.fit(X_train_fraud, y_train_fraud)\n",
        "        y_pred = model.predict(X_test_fraud)\n",
        "        accuracy = accuracy_score(y_test_fraud, y_pred)\n",
        "\n",
        "        # Log parameters and metrics\n",
        "        mlflow.log_params({\n",
        "            'model': name,\n",
        "            'dataset': 'Fraud Data',\n",
        "            'test_size': 0.2,\n",
        "            'random_state': 42\n",
        "        })\n",
        "        mlflow.log_metric('accuracy', accuracy)\n",
        "\n",
        "        # Save the model\n",
        "        mlflow.sklearn.log_model(model, f'{name}_model')\n",
        "\n",
        "        # Print and log classification report\n",
        "        print(f\"Model: {name}\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(classification_report(y_test_fraud, y_pred))\n",
        "        print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLOps Steps\n",
        "### Versioning and Experiment Tracking with MLflow\n",
        "### For versioning and experiment tracking, we'll integrate MLflow. Ensure you have MLflow installed (pip install mlflow) and set up in your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwYbibRUpLFk",
        "outputId": "1d116b38-3544-4179-a70c-9baed7752002"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 0.9972533760585947\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      4349\n",
            "         1.0       0.79      0.55      0.65        20\n",
            "\n",
            "    accuracy                           1.00      4369\n",
            "   macro avg       0.89      0.77      0.82      4369\n",
            "weighted avg       1.00      1.00      1.00      4369\n",
            "\n",
            "============================================================\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.9988555733577478\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      4349\n",
            "         1.0       0.89      0.85      0.87        20\n",
            "\n",
            "    accuracy                           1.00      4369\n",
            "   macro avg       0.95      0.92      0.94      4369\n",
            "weighted avg       1.00      1.00      1.00      4369\n",
            "\n",
            "============================================================\n",
            "Model: Random Forest\n",
            "Accuracy: 0.9990844586861982\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      4349\n",
            "         1.0       1.00      0.80      0.89        20\n",
            "\n",
            "    accuracy                           1.00      4369\n",
            "   macro avg       1.00      0.90      0.94      4369\n",
            "weighted avg       1.00      1.00      1.00      4369\n",
            "\n",
            "============================================================\n",
            "Model: Gradient Boosting\n",
            "Accuracy: 0.9983978027008469\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      4349\n",
            "         1.0       0.84      0.80      0.82        20\n",
            "\n",
            "    accuracy                           1.00      4369\n",
            "   macro avg       0.92      0.90      0.91      4369\n",
            "weighted avg       1.00      1.00      1.00      4369\n",
            "\n",
            "============================================================\n",
            "Model: MLP\n",
            "Accuracy: 0.9965667200732433\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      4349\n",
            "         1.0       0.73      0.40      0.52        20\n",
            "\n",
            "    accuracy                           1.00      4369\n",
            "   macro avg       0.86      0.70      0.76      4369\n",
            "weighted avg       1.00      1.00      1.00      4369\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate models for credit card data\n",
        "for name, model in models.items():\n",
        "    with mlflow.start_run(run_name=f'{name} on Credit Card Data'):\n",
        "        model.fit(X_train_credit, y_train_credit)\n",
        "        y_pred = model.predict(X_test_credit)\n",
        "        accuracy = accuracy_score(y_test_credit, y_pred)\n",
        "\n",
        "        # Log parameters and metrics\n",
        "        mlflow.log_params({\n",
        "            'model': name,\n",
        "            'dataset': 'Credit Card Data',\n",
        "            'test_size': 0.2,\n",
        "            'random_state': 42\n",
        "        })\n",
        "        mlflow.log_metric('accuracy', accuracy)\n",
        "\n",
        "        # Save the model\n",
        "        mlflow.sklearn.log_model(model, f'{name}_model')\n",
        "\n",
        "        # Print and log classification report\n",
        "        print(f\"Model: {name}\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        print(classification_report(y_test_credit, y_pred))\n",
        "        print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
