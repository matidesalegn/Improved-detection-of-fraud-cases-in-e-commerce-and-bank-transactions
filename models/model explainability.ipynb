{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matidesalegn/Improved-detection-of-fraud-cases-in-e-commerce-and-bank-transactions/blob/task-3/models/model%20explainability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E2qkVm1WMw7b",
        "outputId": "8fadde25-1195-4af4-9515-436bb3ccca59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.0.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.4)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install shap\n",
        "!pip install lime\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lua_qA-0Mw7c"
      },
      "source": [
        "Let's outline a step-by-step approach to explainability using both SHAP and LIME:\n",
        "\n",
        "Step 1: Load the Trained Model and Data\n",
        "Assume you have already trained your fraud detection models (Decision Tree, Random Forest, MLP, etc.) and have a dataset ready for explanations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data with specified dtypes to avoid warnings and inspect the data\n",
        "data = pd.read_csv('processed_fraud_data_with_country.csv', low_memory=False)\n",
        "\n",
        "# Print the first few rows to inspect the DataFrame structure\n",
        "print(data.head())\n",
        "\n",
        "# Print the column names to verify the presence of the 'fraud' column\n",
        "print(data.columns)\n",
        "\n",
        "# If the 'fraud' column is present, proceed with the next steps\n",
        "if 'fraud' in data.columns:\n",
        "    X = data.drop(columns=['fraud'])\n",
        "    y = data['fraud']\n",
        "else:\n",
        "    print(\"The 'fraud' column is not found in the dataset.\")\n"
      ],
      "metadata": {
        "id": "YtMch5ywRgyo",
        "outputId": "8609cd2c-e785-4df6-e4a5-e1d459a0c332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id          signup_time        purchase_time  purchase_value  \\\n",
            "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11       -0.160204   \n",
            "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54       -1.142592   \n",
            "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45       -1.197169   \n",
            "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50        0.385567   \n",
            "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53        0.112681   \n",
            "\n",
            "       device_id       age    ip_address  class  ip_address_int  \\\n",
            "0  QVPSPJUOCKZAR  0.679914  7.327584e+08      0       732758368   \n",
            "1  EOGFQPIZPYXFZ  2.304476  3.503114e+08      0       350311387   \n",
            "2  YSSKYOSJHPPLJ  2.304476  2.621474e+09      1      2621473820   \n",
            "3  ATGTXKYKUDUQN  0.911994  3.840542e+09      0      3840542443   \n",
            "4  NAUITBZFJKHWW  1.376155  4.155831e+08      0       415583117   \n",
            "\n",
            "   transaction_count  ...  country_Unknown  country_Uruguay  \\\n",
            "0                0.0  ...            False            False   \n",
            "1                0.0  ...            False            False   \n",
            "2                0.0  ...            False            False   \n",
            "3                0.0  ...             True            False   \n",
            "4                0.0  ...            False            False   \n",
            "\n",
            "   country_Uzbekistan  country_Vanuatu  country_Venezuela  country_Viet Nam  \\\n",
            "0               False            False              False             False   \n",
            "1               False            False              False             False   \n",
            "2               False            False              False             False   \n",
            "3               False            False              False             False   \n",
            "4               False            False              False             False   \n",
            "\n",
            "   country_Virgin Islands (U.S.)  country_Yemen  country_Zambia  \\\n",
            "0                          False          False           False   \n",
            "1                          False          False           False   \n",
            "2                          False          False           False   \n",
            "3                          False          False           False   \n",
            "4                          False          False           False   \n",
            "\n",
            "   country_Zimbabwe  \n",
            "0             False  \n",
            "1             False  \n",
            "2             False  \n",
            "3             False  \n",
            "4             False  \n",
            "\n",
            "[5 rows x 203 columns]\n",
            "Index(['user_id', 'signup_time', 'purchase_time', 'purchase_value',\n",
            "       'device_id', 'age', 'ip_address', 'class', 'ip_address_int',\n",
            "       'transaction_count',\n",
            "       ...\n",
            "       'country_Unknown', 'country_Uruguay', 'country_Uzbekistan',\n",
            "       'country_Vanuatu', 'country_Venezuela', 'country_Viet Nam',\n",
            "       'country_Virgin Islands (U.S.)', 'country_Yemen', 'country_Zambia',\n",
            "       'country_Zimbabwe'],\n",
            "      dtype='object', length=203)\n",
            "The 'fraud' column is not found in the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fr2SMcepMw7e",
        "outputId": "2902bb18-608d-48be-93d8-ff551e9bc271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UFuncTypeError",
          "evalue": "Cannot cast ufunc 'isnan' input from dtype('O') to dtype('bool') with casting rule 'same_kind'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4d178f51ce95>\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'random_forest_model.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'processed_fraud_data_with_country.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mexplainability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelExplainability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Generate plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4d178f51ce95>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, data_path)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Create explainers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer_shap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer_shap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer_lime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlime_tabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLimeTabularExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Non-Fraud'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fraud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscretize_continuous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         X, y, X_missing, flat_output, tree_limit, check_additivity = self._validate_inputs(\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_tree.py\u001b[0m in \u001b[0;36m_validate_inputs\u001b[0;34m(self, X, y, tree_limit, check_additivity)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mX_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unknown instance type: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Passed input data matrix X must have 1 or 2 dimensions!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'isnan' input from dtype('O') to dtype('bool') with casting rule 'same_kind'"
          ]
        }
      ],
      "source": [
        "class ModelExplainability:\n",
        "    def __init__(self, model_path, data_path):\n",
        "        self.model_path = model_path\n",
        "        self.data_path = data_path\n",
        "\n",
        "        # Load and prepare data\n",
        "        self.data = pd.read_csv(data_path, low_memory=False)\n",
        "        if 'class' not in self.data.columns:\n",
        "            raise KeyError(\"The 'class' column is not found in the dataset.\")\n",
        "\n",
        "        # Convert datetime columns to numerical features\n",
        "        self.data['signup_time'] = pd.to_datetime(self.data['signup_time'])\n",
        "        self.data['purchase_time'] = pd.to_datetime(self.data['purchase_time'])\n",
        "        self.data['signup_time'] = (self.data['signup_time'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
        "        self.data['purchase_time'] = (self.data['purchase_time'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
        "\n",
        "        # Separate features into numeric and categorical\n",
        "        self.X = self.data.drop(columns=['class'])\n",
        "        self.y = self.data['class']\n",
        "        self.numeric_features = self.X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        self.categorical_features = self.X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "        # Define preprocessing for numeric and categorical features\n",
        "        numeric_transformer = Pipeline(steps=[\n",
        "            ('imputer', 'passthrough')  # No transformation, but could add scalers or imputers\n",
        "        ])\n",
        "\n",
        "        categorical_transformer = Pipeline(steps=[\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ])\n",
        "\n",
        "        # Bundle preprocessing for numeric and categorical features\n",
        "        self.preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numeric_transformer, self.numeric_features),\n",
        "                ('cat', categorical_transformer, self.categorical_features)\n",
        "            ])\n",
        "\n",
        "        # Define the model pipeline\n",
        "        self.model_pipeline = Pipeline(steps=[\n",
        "            ('preprocessor', self.preprocessor),\n",
        "            ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "        ])\n",
        "\n",
        "        # Split data\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.3, random_state=42)\n",
        "\n",
        "        # Load or train model\n",
        "        try:\n",
        "            self.model = joblib.load(model_path)\n",
        "        except FileNotFoundError:\n",
        "            self.model_pipeline.fit(self.X_train, self.y_train)\n",
        "            joblib.dump(self.model_pipeline, model_path)\n",
        "            self.model = self.model_pipeline\n",
        "\n",
        "        # Create explainers\n",
        "        self.explainer_shap = shap.TreeExplainer(self.model.named_steps['classifier'])\n",
        "        self.shap_values = self.explainer_shap.shap_values(self.model.named_steps['preprocessor'].transform(self.X_test))\n",
        "        self.explainer_lime = lime.lime_tabular.LimeTabularExplainer(self.X_test.values, feature_names=self.X_test.columns, class_names=['Non-Fraud', 'Fraud'], discretize_continuous=True)\n",
        "\n",
        "    def shap_summary_plot(self):\n",
        "        shap.summary_plot(self.shap_values, self.X_test)\n",
        "\n",
        "    def shap_force_plot(self, index):\n",
        "        shap.force_plot(self.explainer_shap.expected_value[1], self.shap_values[1][index], self.X_test.iloc[index], matplotlib=True)\n",
        "\n",
        "    def shap_dependence_plot(self, feature):\n",
        "        shap.dependence_plot(feature, self.shap_values[1], self.X_test)\n",
        "\n",
        "    def lime_explanation(self, index):\n",
        "        exp = self.explainer_lime.explain_instance(self.X_test.iloc[index].values, self.model.predict_proba, num_features=10)\n",
        "        exp.show_in_notebook(show_table=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = 'random_forest_model.pkl'\n",
        "    data_path = 'processed_fraud_data_with_country.csv'\n",
        "    explainability = ModelExplainability(model_path, data_path)\n",
        "\n",
        "    # Generate plots\n",
        "    explainability.shap_summary_plot()\n",
        "    explainability.shap_force_plot(0)\n",
        "    explainability.shap_dependence_plot('purchase_value')  # Example feature\n",
        "    explainability.lime_explanation(0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}